{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTXfyh4ZGCDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import csv\n",
        "from icdmappings import Mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vf-V89hKtmW"
      },
      "outputs": [],
      "source": [
        "# directory where the MIMIC-III data 'ADMISSIONS.csv', 'DIAGNOSES_ICD.csv', 'NOTEEVENTS.csv' are stored\n",
        "mimic3_path = './MIMIC'\n",
        "\n",
        "# directory where the filtered data will be stored\n",
        "output_path = './MIMIC/filterd_data'\n",
        "\n",
        "# directory where the ccs_definitions are stored\n",
        "phenotype_definitions = './MIMIC/hcup_ccs_2015_definitions.yaml'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Goal:\n",
        "\n",
        "process the admission table for readmission prediction;\n",
        "\n",
        "filter out admissions based on admission types, patients' ages, and relation with diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FoiVCgVEyYk"
      },
      "outputs": [],
      "source": [
        "def dataframe_from_csv(path, header=0, index_col=0):\n",
        "    return pd.read_csv(path, header=header, index_col=index_col)\n",
        "\n",
        "def read_patients_table(mimic3_path):\n",
        "    pats = dataframe_from_csv(os.path.join(mimic3_path, 'PATIENTS.csv'))\n",
        "    pats = pats[['SUBJECT_ID', 'GENDER', 'DOB', 'DOD']]\n",
        "    pats.DOB = pd.to_datetime(pats.DOB)\n",
        "    pats.DOD = pd.to_datetime(pats.DOD)\n",
        "    return pats\n",
        "\n",
        "\n",
        "def read_admissions_table(mimic3_path):\n",
        "    admits = dataframe_from_csv(os.path.join(mimic3_path, 'ADMISSIONS.csv'))\n",
        "    #admits = admits[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'ETHNICITY', 'DIAGNOSIS']]\n",
        "    admits.ADMITTIME = pd.to_datetime(admits.ADMITTIME, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "    admits.DISCHTIME = pd.to_datetime(admits.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
        "    admits.DEATHTIME = pd.to_datetime(admits.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
        "\n",
        "    admits = admits.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
        "    admits = admits.reset_index(drop = True)\n",
        "\n",
        "    admits['NEXT_ADMITTIME'] = admits.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
        "    admits['NEXT_ADMISSION_TYPE'] = admits.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)\n",
        "\n",
        "    rows = admits.NEXT_ADMISSION_TYPE == 'ELECTIVE'\n",
        "    admits.loc[rows,'NEXT_ADMITTIME'] = pd.NaT\n",
        "    admits.loc[rows,'NEXT_ADMISSION_TYPE'] = np.NaN\n",
        "\n",
        "    admits = admits.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
        "\n",
        "    admits[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = admits.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')\n",
        "    admits['DAYS_NEXT_ADMIT']=  (admits.NEXT_ADMITTIME - admits.DISCHTIME).dt.total_seconds()/(24*60*60)\n",
        "    admits['OUTPUT_LABEL'] = (admits.DAYS_NEXT_ADMIT < 30).astype('int')\n",
        "    return admits\n",
        "\n",
        "\n",
        "def read_icustays_table(mimic3_path):\n",
        "    stays = dataframe_from_csv(os.path.join(mimic3_path, 'ICUSTAYS.csv'))\n",
        "    stays.INTIME = pd.to_datetime(stays.INTIME)\n",
        "    stays.OUTTIME = pd.to_datetime(stays.OUTTIME)\n",
        "    return stays\n",
        "\n",
        "\n",
        "def read_icd_diagnoses_table(mimic3_path):\n",
        "    codes = dataframe_from_csv(os.path.join(mimic3_path, 'D_ICD_DIAGNOSES.csv'))\n",
        "    codes = codes[['ICD9_CODE', 'SHORT_TITLE', 'LONG_TITLE']]\n",
        "    diagnoses = dataframe_from_csv(os.path.join(mimic3_path, 'DIAGNOSES_ICD.csv'))\n",
        "    diagnoses = diagnoses.merge(codes, how='inner', left_on='ICD9_CODE', right_on='ICD9_CODE')\n",
        "    diagnoses[['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM']] = diagnoses[['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM']].astype(int)\n",
        "    return diagnoses\n",
        "\n",
        "# def count_icd_codes(diagnoses, output_path=None):\n",
        "#     codes = diagnoses[['ICD9_CODE', 'SHORT_TITLE', 'LONG_TITLE']].drop_duplicates().set_index('ICD9_CODE')\n",
        "#     codes['COUNT'] = diagnoses.groupby('ICD9_CODE')['ICUSTAY_ID'].count()\n",
        "#     codes.COUNT = codes.COUNT.fillna(0).astype(int)\n",
        "#     codes = codes[codes.COUNT > 0]\n",
        "#     if output_path:\n",
        "#         codes.to_csv(output_path, index_label='ICD9_CODE')\n",
        "#     return codes.sort_values('COUNT', ascending=False).reset_index()\n",
        "\n",
        "\n",
        "# def remove_icustays_with_transfers(stays):\n",
        "#     stays = stays[(stays.FIRST_WARDID == stays.LAST_WARDID) & (stays.FIRST_CAREUNIT == stays.LAST_CAREUNIT)]\n",
        "#     return stays[['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'LAST_CAREUNIT', 'DBSOURCE', 'INTIME', 'OUTTIME', 'LOS']]\n",
        "\n",
        "\n",
        "def merge_on_subject(table1, table2):\n",
        "    return table1.merge(table2, how='inner', left_on=['SUBJECT_ID'], right_on=['SUBJECT_ID'])\n",
        "\n",
        "\n",
        "def merge_on_subject_admission(table1, table2):\n",
        "    return table1.merge(table2, how='inner', left_on=['SUBJECT_ID', 'HADM_ID'], right_on=['SUBJECT_ID', 'HADM_ID'])\n",
        "\n",
        "def diagnoses_groupby_adm(diagnoses): # column:[hadm_id, icd9_codes, ccs_codes]\n",
        "  diagnoses_adm = diagnoses.groupby('HADM_ID')['ICD9_CODE'].apply(list).reset_index(name='ICD9_CODEs') #merge diagnosis codes of each admissions into a list\n",
        "  mapper = Mapper()\n",
        "  icd9list = list(diagnoses_adm.ICD9_CODEs)\n",
        "  ccslist = []\n",
        "  for codes in icd9list:\n",
        "    ccslist.append(mapper.map(codes, source='icd9', target='ccs'))\n",
        "\n",
        "  diagnoses_adm['CCS_CODES'] = ccslist\n",
        "  return diagnoses_adm\n",
        "\n",
        "def add_age_to_icustays(stays):\n",
        "    stays['AGE'] = stays.apply(lambda e: (e['INTIME'].to_pydatetime()\n",
        "                                          - e['DOB'].to_pydatetime()).total_seconds() / 3600.0 / 24.0 / 365.0,\n",
        "                               axis=1)\n",
        "    stays.loc[stays.AGE < 0, 'AGE'] = 90\n",
        "    return stays\n",
        "\n",
        "# def filter_admissions_on_nb_icustays(stays, min_nb_stays=1, max_nb_stays=1):\n",
        "#     to_keep = stays.groupby('HADM_ID').count()[['ICUSTAY_ID']].reset_index()\n",
        "#     to_keep = to_keep[(to_keep.ICUSTAY_ID >= min_nb_stays) & (to_keep.ICUSTAY_ID <= max_nb_stays)][['HADM_ID']]\n",
        "#     stays = stays.merge(to_keep, how='inner', left_on='HADM_ID', right_on='HADM_ID')\n",
        "#     return stays\n",
        "\n",
        "def filter_icustays_on_age(stays, min_age=18, max_age=100):\n",
        "    stays = stays[(stays.AGE >= min_age) & (stays.AGE <= max_age)]\n",
        "    return stays\n",
        "\n",
        "\n",
        "# def filter_diagnoses_on_stays(diagnoses, stays):\n",
        "#     return diagnoses.merge(stays[['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID']].drop_duplicates(), how='inner',\n",
        "#                            left_on=['SUBJECT_ID', 'HADM_ID'], right_on=['SUBJECT_ID', 'HADM_ID'])\n",
        "\n",
        "def filter_diagnoses_on_admits(diagnoses, admits):\n",
        "    return diagnoses.merge(admits[['SUBJECT_ID', 'HADM_ID']], how='inner',\n",
        "                           left_on=['SUBJECT_ID', 'HADM_ID'], right_on=['SUBJECT_ID', 'HADM_ID'])\n",
        "\n",
        "def filter_admits_on_ccsbenchmark(admits, phenotypes):\n",
        "    return admits.merge(phenotypes[['HADM_ID']], how='inner',\n",
        "                           left_on=['HADM_ID'], right_on=['HADM_ID'])\n",
        "\n",
        "def add_hcup_ccs_2015_groups(diagnoses, definitions):\n",
        "    def_map = {}\n",
        "    for dx in definitions:\n",
        "        for code in definitions[dx]['codes']:\n",
        "            def_map[code] = (dx, definitions[dx]['use_in_benchmark'])\n",
        "    diagnoses['HCUP_CCS_2015'] = diagnoses.ICD9_CODE.apply(lambda c: def_map[c][0] if c in def_map else None)\n",
        "    diagnoses['USE_IN_BENCHMARK'] = diagnoses.ICD9_CODE.apply(lambda c: int(def_map[c][1]) if c in def_map else None)\n",
        "    return diagnoses\n",
        "\n",
        "# def add_inhospital_mortality_to_icustays(stays):\n",
        "#     mortality = stays.DOD.notnull() & ((stays.ADMITTIME <= stays.DOD) & (stays.DISCHTIME >= stays.DOD))\n",
        "#     mortality = mortality | (stays.DEATHTIME.notnull() & ((stays.ADMITTIME <= stays.DEATHTIME) & (stays.DISCHTIME >= stays.DEATHTIME)))\n",
        "#     stays['MORTALITY'] = mortality.astype(int)\n",
        "#     stays['MORTALITY_INHOSPITAL'] = stays['MORTALITY']\n",
        "#     return stays\n",
        "\n",
        "\n",
        "# def add_inunit_mortality_to_icustays(stays):\n",
        "#     mortality = stays.DOD.notnull() & ((stays.INTIME <= stays.DOD) & (stays.OUTTIME >= stays.DOD))\n",
        "#     mortality = mortality | (stays.DEATHTIME.notnull() & ((stays.INTIME <= stays.DEATHTIME) & (stays.OUTTIME >= stays.DEATHTIME)))\n",
        "#     stays['MORTALITY_INUNIT'] = mortality.astype(int)\n",
        "#     return stays\n",
        "\n",
        "def make_phenotype_label_matrix(phenotypes):#, stays=None):\n",
        "    phenotypes = phenotypes[['HADM_ID', 'HCUP_CCS_2015']].loc[phenotypes.USE_IN_BENCHMARK > 0].drop_duplicates()\n",
        "    phenotypes['VALUE'] = 1\n",
        "    phenotypes = phenotypes.pivot(index='HADM_ID', columns='HCUP_CCS_2015', values='VALUE')\n",
        "    # if stays is not None:\n",
        "    #     phenotypes = phenotypes.reindex(stays.ICUSTAY_ID.sort_values())\n",
        "    return phenotypes.fillna(0).astype(int).sort_index(axis=0).sort_index(axis=1)\n",
        "\n",
        "def remove_admissions_with_newborns_and_death(admits):\n",
        "  admits = admits[admits['ADMISSION_TYPE']!='NEWBORN']\n",
        "  admits = admits[admits.DEATHTIME.isnull()]\n",
        "  admits['DURATION'] = (admits['DISCHTIME']-admits['ADMITTIME']).dt.total_seconds()/(24*60*60)\n",
        "\n",
        "  admits = admits.reset_index(drop = True)\n",
        "  return admits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4fZb5vUGqZF",
        "outputId": "b7a37975-47f7-4cdb-f66a-c07db4d035c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START:\n",
            "\tICUSTAY_IDs: 61532\n",
            "\tHADM_IDs: 57786\n",
            "\tSUBJECT_IDs: 46476\n"
          ]
        }
      ],
      "source": [
        "patients = read_patients_table(mimic3_path)\n",
        "admits = read_admissions_table(mimic3_path)\n",
        "stays = read_icustays_table(mimic3_path)\n",
        "\n",
        "print('START:\\n\\tICUSTAY_IDs: {}\\n\\tHADM_IDs: {}\\n\\tSUBJECT_IDs: {}'.format(stays.ICUSTAY_ID.unique().shape[0],\n",
        "          stays.HADM_ID.unique().shape[0], stays.SUBJECT_ID.unique().shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz9_WH0X5Z0T",
        "outputId": "c2de5c61-8a61-4c28-fc3d-5f02fbc8fa60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HADM_IDs: 45321\n"
          ]
        }
      ],
      "source": [
        "# remove newborn and death case in admmisions.csv\n",
        "admits = remove_admissions_with_newborns_and_death(admits)\n",
        "\n",
        "# double check...\n",
        "if admits.DEATHTIME.isnull().unique()[0] != True:\n",
        "  raise ValueError(\"There are still some death cases\")\n",
        "\n",
        "#admits.to_csv(os.path.join(output_path_ig, 'admissions.csv'))\n",
        "print('HADM_IDs: {}'.format(admits.HADM_ID.unique().shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVtC3yIZJDWn"
      },
      "outputs": [],
      "source": [
        "# obtain age information from 'stay' and gender informaton from 'patient'\n",
        "stays = merge_on_subject(stays, patients)\n",
        "stays_age = add_age_to_icustays(stays).drop_duplicates(subset=['HADM_ID'])\n",
        "# keep 'age' in  (18,100)\n",
        "stays_age = filter_icustays_on_age(stays_age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSeXE-qO4rns"
      },
      "outputs": [],
      "source": [
        "admits_age = pd.merge(admits[['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','DAYS_NEXT_ADMIT','NEXT_ADMITTIME','ADMISSION_TYPE','DEATHTIME','OUTPUT_LABEL','DURATION','DIAGNOSIS']],\n",
        "                        stays_age[['SUBJECT_ID','HADM_ID','GENDER','AGE']],\n",
        "                        on = ['SUBJECT_ID','HADM_ID'],\n",
        "                        how = 'left').drop_duplicates(subset=['HADM_ID']) # 45321 admissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHm4M0SRQy3T"
      },
      "outputs": [],
      "source": [
        "# merge information of diganosis codes and their description\n",
        "diagnoses = read_icd_diagnoses_table(mimic3_path)\n",
        "# group by diagnoses codes for each admission, store them in list, and map them to ccs codes\n",
        "diagnoses_adm = diagnoses_groupby_adm(diagnoses) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynjo-KJFGGaL"
      },
      "outputs": [],
      "source": [
        "admits_diagnosis = pd.merge(admits_age, diagnoses_adm, on=['HADM_ID'], how='left') #add diagnosis information to each admission\n",
        "admits_diagnosis = admits_diagnosis[admits_diagnosis['ICD9_CODEs'].isnull() != True] # filter 10 admissions: 45302 left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsEEMwKpZE_c"
      },
      "outputs": [],
      "source": [
        "diagnosis_final = filter_diagnoses_on_admits(diagnoses, admits_diagnosis)\n",
        "phenotypes = add_hcup_ccs_2015_groups(diagnosis_final, yaml.safe_load(open(phenotype_definitions, 'r')))\n",
        "adm_phenotypes = make_phenotype_label_matrix(phenotypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giNXedKL_Uns"
      },
      "outputs": [],
      "source": [
        "# add column HADM_ID based on index(hadm_id)\n",
        "col = list(adm_phenotypes.columns)\n",
        "hadm = list(adm_phenotypes.index)\n",
        "adm_phenotypes_col_hadmid = pd.DataFrame(adm_phenotypes, columns=col, index=hadm)\n",
        "adm_phenotypes_col_hadmid.reset_index(inplace=True)\n",
        "adm_phenotypes_col_hadmid = adm_phenotypes_col_hadmid.rename(columns = {'index':'HADM_ID'})\n",
        "adm_phenotypes_col_hadmid.to_csv(os.path.join(output_path, 'phenotypes_for_each_adm_final.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7jpCeOIBmLn"
      },
      "outputs": [],
      "source": [
        "admits_final = filter_admits_on_ccsbenchmark(admits_diagnosis, adm_phenotypes_col_hadmid)\n",
        "admits_final.to_csv(os.path.join(output_path, 'admits_final.csv'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
