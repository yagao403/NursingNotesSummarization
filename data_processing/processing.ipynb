{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c746f07",
      "metadata": {
        "id": "5c746f07"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "#from transformers import AutoTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027e5087",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "027e5087",
        "outputId": "f2db4b7d-62d7-47aa-8391-8f4072839169",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# load note events and admision records\n",
        "PATH_DATA = './MIMIC'\n",
        "PATH_FILTERED_DATA = './MIMIC/filterd_data'\n",
        "df_notes = pd.read_csv(os.path.join(PATH_DATA, 'NOTEEVENTS.csv'))\n",
        "df_adm = pd.read_csv(os.path.join(PATH_FILTERED_DATA, 'admits_final.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OhdbjgRaZ4X_",
      "metadata": {
        "id": "OhdbjgRaZ4X_"
      },
      "outputs": [],
      "source": [
        "def merge_on_subject(table1, table2):\n",
        "    return table1.merge(table2['HADM_ID'], how='inner', left_on=['HADM_ID'], right_on=['HADM_ID'])\n",
        "\n",
        "def preprocess1(x):\n",
        "    y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n",
        "    y=re.sub('[0-9]+\\.','',y) #remove 1.2. since the segmenter segments based on this\n",
        "    y=re.sub('dr\\.','doctor',y)\n",
        "    y=re.sub('m\\.d\\.','md',y)\n",
        "    y=re.sub('admission date:','',y)\n",
        "    y=re.sub('discharge date:','',y)\n",
        "    y=re.sub('--|__|==','',y)\n",
        "    #y=re.sub('~','',y)\n",
        "    return y\n",
        "\n",
        "def preprocessing(df):\n",
        "    df['TEXT']=df['TEXT'].fillna(' ')\n",
        "    df['TEXT']=df['TEXT'].str.replace('\\n',' ')\n",
        "    df['TEXT']=df['TEXT'].str.replace('\\r',' ')\n",
        "    df['TEXT']=df['TEXT'].apply(str.strip)\n",
        "    df['TEXT']=df['TEXT'].str.lower()\n",
        "\n",
        "    df['TEXT']=df['TEXT'].apply(lambda x: preprocess1(x))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def tokens_count(tk,txt):\n",
        "  ids = tk(txt)['input_ids']\n",
        "  return len(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UMy_oiODItg8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMy_oiODItg8",
        "outputId": "adb98372-f8f5-4af3-f608-b1b7bc3b7c37"
      },
      "outputs": [],
      "source": [
        "df_notes = df_notes[df_notes['HADM_ID'].notnull()]\n",
        "df_notes.HADM_ID = df_notes.HADM_ID.astype(int)\n",
        "\n",
        "# keep only nursing/others\n",
        "df_notes = df_notes[df_notes['CATEGORY'] == 'Nursing/other']\n",
        "df_notes = df_notes.reset_index(drop = True)\n",
        "\n",
        "# sort the note\n",
        "df_notes.CHARTTIME = pd.to_datetime(df_notes.CHARTTIME, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "df_notes.sort_values(by=['SUBJECT_ID','HADM_ID', 'CHARTTIME'], inplace=True)\n",
        "df_notes.reset_index(drop = True)\n",
        "\n",
        "# preprocess notes\n",
        "preprocessing(df_notes)\n",
        "\n",
        "# group by notes for each admissions, results are stored in a new dataframe\n",
        "df_nursing_for_each_adm = pd.DataFrame(df_notes.groupby('HADM_ID')['TEXT'].apply(list)).reset_index()\n",
        "\n",
        "# filter out notes which are not in admission table\n",
        "HADM_ID_adm = list(df_adm.HADM_ID)\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm[df_nursing_for_each_adm['HADM_ID'].isin(HADM_ID_adm)]\n",
        "\n",
        "# filter out the admissions having notes over 100\n",
        "note_list = list(df_nursing_for_each_adm.TEXT)\n",
        "id_list = list(df_nursing_for_each_adm.HADM_ID)\n",
        "id_selected_list = []\n",
        "note_len = []\n",
        "for i, note in enumerate(note_list):\n",
        "  if len(note)<100:\n",
        "    id_selected_list.append(id_list[i])\n",
        "\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm[df_nursing_for_each_adm['HADM_ID'].isin(id_selected_list)]\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm.reset_index(drop=True) \n",
        "df_nursing_for_each_adm.to_csv(os.path.join(PATH_FILTERED_DATA, 'nursing_notes_bf_length_limits.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nuWj8FUPSfWt",
      "metadata": {
        "id": "nuWj8FUPSfWt"
      },
      "outputs": [],
      "source": [
        "# find admissions with notes shorter than 50 tokens\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "notes = list(df_nursing_for_each_adm['TEXT'])\n",
        "id_list = list(df_nursing_for_each_adm['HADM_ID'])\n",
        "\n",
        "over_limit = []\n",
        "over_token_num = []\n",
        "\n",
        "for i, notes_list in enumerate(notes):\n",
        "  print(i)\n",
        "  for note in notes_list:\n",
        "    tk_count = tokens_count(tokenizer, note)\n",
        "    if tk_count < 50 :\n",
        "      over_token_num.append(tk_count)\n",
        "      over_limit.append(id_list[i])\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jqlfCJON7_ZB",
      "metadata": {
        "id": "jqlfCJON7_ZB"
      },
      "outputs": [],
      "source": [
        "# for an admission, check the number of notes in it are very short\n",
        "num_of_note_shorter = []\n",
        "\n",
        "for id in over_limit:\n",
        "  n_list = list(df_nursing_for_each_adm[df_nursing_for_each_adm['HADM_ID']==id]['TEXT'])[0]\n",
        "  num_of_note = 0\n",
        "  for n in n_list:\n",
        "    num_of_tk = tokens_count(tokenizer,n)\n",
        "    if num_of_tk<50:\n",
        "      num_of_note += 1\n",
        "  num_of_note_shorter.append(num_of_note)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1EF8Nh6z_94W",
      "metadata": {
        "id": "1EF8Nh6z_94W"
      },
      "outputs": [],
      "source": [
        "# if the number of short note takes more than 20%, we remove this admission. Otherwize, we delete the short note from all notes of this admission\n",
        "len_of_ad = []\n",
        "for id in over_limit:\n",
        "  n_list = list(df_nursing_for_each_adm[df_nursing_for_each_adm['HADM_ID']==id]['TEXT'])[0]\n",
        "  len_of_ad.append(len(n_list))\n",
        "\n",
        "alot_shorter = []\n",
        "note_tobe_del = []\n",
        "for i in range(len(len_of_ad)):\n",
        "  if num_of_note_shorter[i]/len_of_ad[i] > 0.2:\n",
        "    alot_shorter.append(over_limit[i])\n",
        "  else:\n",
        "    note_tobe_del.append(over_limit[i])\n",
        "\n",
        "# remove the admissions\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm[~ df_nursing_for_each_adm['HADM_ID'].isin(alot_shorter)]\n",
        "\n",
        "# delete the short notes from all notes of this admission\n",
        "for i in note_tobe_del:\n",
        "  n_list = list(df_nursing_for_each_adm[df_nursing_for_each_adm['HADM_ID']==i]['TEXT'])[0]\n",
        "  del_index = []\n",
        "  for j in range(len(n_list)):\n",
        "    if tokens_count(tokenizer,n_list[j]) < 50:\n",
        "      del_index.append(j)\n",
        "  for k in sorted(del_index, reverse=True):\n",
        "    del n_list[k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VBsE6x0p5AIg",
      "metadata": {
        "id": "VBsE6x0p5AIg"
      },
      "outputs": [],
      "source": [
        "# find admissions with notes longer than 800 tokens\n",
        "notes = list(df_nursing_for_each_adm['TEXT'])\n",
        "id_list = list(df_nursing_for_each_adm['HADM_ID'])\n",
        "\n",
        "over_limit = []\n",
        "over_token_num = []\n",
        "\n",
        "for i, notes_list in enumerate(notes):\n",
        "  print(i)\n",
        "  for note in notes_list:\n",
        "    tk_count = tokens_count(tokenizer, note)\n",
        "    if tk_count > 800 :\n",
        "      over_token_num.append(tk_count)\n",
        "      over_limit.append(id_list[i])\n",
        "      break\n",
        "\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm[~ df_nursing_for_each_adm['HADM_ID'].isin(over_limit)]\n",
        "df_nursing_for_each_adm = df_nursing_for_each_adm.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9zDLPfTPTC7m",
      "metadata": {
        "id": "9zDLPfTPTC7m"
      },
      "outputs": [],
      "source": [
        "# convert note list of each admission to string\n",
        "notes_list = list(df_nursing_for_each_adm['TEXT'])\n",
        "for i, n in enumerate(notes_list):\n",
        "  s = '\\n'.join(n)\n",
        "  df_nursing_for_each_adm.iloc[i, 1] = s\n",
        "\n",
        "df_nursing_for_each_adm.to_csv(os.path.join(PATH_FILTERED_DATA, 'nursing_notes_af_length_limits.csv'))\n",
        "\n",
        "# keep admissions in note table\n",
        "hadm_id = list(df_nursing_for_each_adm['HADM_ID'])\n",
        "df_adm = df_adm[df_adm['HADM_ID'].isin(hadm_id)] # 16493 remained\n",
        "\n",
        "df_adm.to_csv(os.path.join(PATH_FILTERED_DATA, 'admits_final_af_note_filter.csv'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
